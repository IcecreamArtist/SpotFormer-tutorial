{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "337d82dd",
   "metadata": {},
   "source": [
    "# Tutorial 2: Model pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a0df62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "from argparse import Namespace\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
    "from dateutil import tz\n",
    "from einops import rearrange\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import (EarlyStopping, LearningRateMonitor,\n",
    "                                         ModelCheckpoint, Callback)\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from model.datasets.data_module import DataModule\n",
    "from model.datasets.pretrain_dataset import (SpatialRadiusDataset, \n",
    "                                             my_collate_fn)\n",
    "from model.emb_gen.backbones.encoder import BertEncoder\n",
    "from step1_pretrain import Omics, EpochCallback\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "from model.constants import *\n",
    "\n",
    "is_debug = False\n",
    "is_save_ckpt = True\n",
    "if is_debug:\n",
    "    os.environ['WANDB_MODE'] = 'disabled'\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5519b0d5",
   "metadata": {},
   "source": [
    "## Initialize the args and fix seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b0ab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the GPU to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Directly specify the training parameters from the original command\n",
    "args = Namespace(\n",
    "    gpus=1,\n",
    "    batch_size=500,\n",
    "    epochs=3,\n",
    "    max_epochs=3,\n",
    "    mask_ratio=0.4,\n",
    "    experiment_name=\"cosmx_1\",\n",
    "    learning_rate=5e-6,\n",
    "    config=os.path.join(BASE_DIR, '../../configs/bert_config.json'),\n",
    "    dataset_name=\"cosmx_lung5_rep1\",\n",
    "    fold=\"fold_1\",\n",
    "    max_points=20,\n",
    "    radius=20,\n",
    "    mask_function=\"dynamic\",\n",
    "    num_workers=10,\n",
    "    seed=42,\n",
    "    data_pct=1.0,\n",
    "    deterministic=True,\n",
    "    freeze_bert=False,\n",
    "    emb_dim=192,\n",
    "    lambda_1=1.0,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.05,\n",
    "    output_dim=768,\n",
    "    hidden_dim=768,\n",
    "    ct_obs=\"cell_class\",\n",
    "    ckpt_path=None\n",
    ")\n",
    "\n",
    "# fix the seed to ensure reproducibility of the experiment\n",
    "seed_everything(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0a015b",
   "metadata": {},
   "source": [
    "## Set fold split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f5733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset_name == 'seqfish': # dataset: seqFISH+ 3T3\n",
    "    train_split = SEQFISH_FOLDS[args.fold]['train']\n",
    "    val_split = SEQFISH_FOLDS[args.fold]['val']\n",
    "elif args.dataset_name == 'merfish': # MERFISH U2-OS\n",
    "    train_split = MERFISH_FOLDS[args.fold]['train']\n",
    "    val_split = MERFISH_FOLDS[args.fold]['val']\n",
    "elif args.dataset_name == 'mop1' or args.dataset_name == 'mop1_filtered': # dataset: MOp\n",
    "    train_split = MOP_FOLDS1[args.fold]['train']\n",
    "    val_split = MOP_FOLDS1[args.fold]['val']\n",
    "elif args.dataset_name == 'cosmx_lung5_rep1': # dataset: CosMx lung\n",
    "    train_split = COSMX_FOLDS51[args.fold]['train']\n",
    "    val_split = COSMX_FOLDS51[args.fold]['val']\n",
    "elif args.dataset_name == 'AD_64g_m9721' or args.dataset_name == 'AD_64g_m9781' \\\n",
    "    or args.dataset_name == 'AD_64g_m9919' or args.dataset_name == 'AD_64g_m9930': # dataset: STARmap PLUS\n",
    "    train_split = AD_FOLDS[args.fold]['train']\n",
    "    val_split = AD_FOLDS[args.fold]['val']\n",
    "elif args.dataset_name == 'xenium_hbc1' or args.dataset_name == 'xenium_hbc1_rep2': # dataset: Xenium HBC\n",
    "    train_split = XENIUM_HBC_FOLDS1[args.fold]['train']\n",
    "    val_split = XENIUM_HBC_FOLDS1[args.fold]['val']\n",
    "elif args.dataset_name == 'AD_2766g_m9498' or args.dataset_name == 'AD_2766g_m9707' \\\n",
    "    or args.dataset_name == 'AD_2766g_m9735' or args.dataset_name == 'AD_2766g_m9494' \\\n",
    "        or args.dataset_name == 'AD_2766g_m11346' or args.dataset_name == 'AD_2766g_m9723' \\\n",
    "            or args.dataset_name == 'AD_2766g_m11351': # dataset: STARmap PLUS\n",
    "    train_split = AD_FOLDS[args.fold]['train']\n",
    "    val_split = AD_FOLDS[args.fold]['val']\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016e1b7e",
   "metadata": {},
   "source": [
    "## Initialize dataloaders and SpotFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4020a2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_callback = EpochCallback()\n",
    "\n",
    "datamodule = DataModule(SpatialRadiusDataset, my_collate_fn,\n",
    "                        args.data_pct, args.batch_size, \n",
    "                        args.num_workers, radius=args.radius, \n",
    "                        mask_ratio=args.mask_ratio, mask_function=args.mask_function,\n",
    "                        dataset_name=args.dataset_name, max_points=args.max_points,\n",
    "                        train_split=train_split, val_split=val_split,\n",
    "                        label_type='pretrain', callback=epoch_callback)\n",
    "# Add load from checkpoint\n",
    "if args.ckpt_path:\n",
    "    model = Omics.load_from_checkpoint(args.ckpt_path)\n",
    "else:\n",
    "    model = Omics(**args.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fda6ecc",
   "metadata": {},
   "source": [
    "## Initialize the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291b7b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current time\n",
    "now = datetime.datetime.now(tz.tzlocal())\n",
    "extension = now.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "ckpt_dir = os.path.join(\n",
    "    BASE_DIR, f\"../../../data/ckpts/Omics/{args.experiment_name}_{args.dataset_name}_{extension}\")\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "callbacks = [\n",
    "    LearningRateMonitor(logging_interval=\"step\"),\n",
    "    ModelCheckpoint(monitor=\"val_loss\", dirpath=ckpt_dir,\n",
    "                    save_last=False, mode=\"min\", save_top_k=1),\n",
    "    EarlyStopping(monitor=\"val_loss\", min_delta=0.,\n",
    "                    patience=5, verbose=False, mode=\"min\"),\n",
    "    epoch_callback\n",
    "]\n",
    "logger_dir = os.path.join(\n",
    "    BASE_DIR, f\"../../../data\")\n",
    "os.makedirs(logger_dir, exist_ok=True)\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"SpotFormer_pretrain\", save_dir=logger_dir, \n",
    "    name=args.experiment_name+\"_\"+args.dataset_name+\"_\"+extension)\n",
    "trainer = Trainer.from_argparse_args(\n",
    "    args=args,\n",
    "    callbacks=callbacks,\n",
    "    logger=wandb_logger,\n",
    "    precision=16,\n",
    "    gradient_clip_val=0.5)\n",
    "\n",
    "model.training_steps = model.num_training_steps(trainer, datamodule)\n",
    "print('number of model training steps: ', model.training_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba07a329",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a79e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, datamodule=datamodule)\n",
    "\n",
    "if is_save_ckpt:\n",
    "    best_ckpt_path = os.path.join(ckpt_dir, \"best_ckpts.yaml\")\n",
    "    callbacks[1].to_yaml(filepath=best_ckpt_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
