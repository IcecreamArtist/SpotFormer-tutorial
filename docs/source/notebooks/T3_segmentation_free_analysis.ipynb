{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c2404bc",
   "metadata": {},
   "source": [
    "# Tutorial 6: Segmentation-free analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abf1c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import argparse\n",
    "import logging\n",
    "from omics.constants import *\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.spatial import cKDTree\n",
    "import scanpy as sc\n",
    "from pytorch_lightning.callbacks import (EarlyStopping, LearningRateMonitor,\n",
    "                                         ModelCheckpoint, Callback)\n",
    "# import squidpy as sq\n",
    "import torch.nn as nn\n",
    "from math import exp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from argparse import Namespace\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from omics.datasets.data_module import testDataModule as DataModule\n",
    "import hashlib\n",
    "import anndata as ad\n",
    "from omics.Finetune.finetune_fold_83 import Omics\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import (EarlyStopping, LearningRateMonitor,\n",
    "                                         ModelCheckpoint)\n",
    "from argparse import ArgumentParser\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import logging\n",
    "import joblib\n",
    "import umap\n",
    "from sklearn.manifold import TSNE\n",
    "import json\n",
    "\n",
    "from visualize import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fd7908",
   "metadata": {},
   "source": [
    "## Initialize configs and fix seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92682e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 设置环境变量\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"8\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"8\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"8\"\n",
    "os.environ[\"NUMBA_NUM_THREADS\"] = \"8\"\n",
    "os.environ[\"OMP_DYNAMIC\"] = \"FALSE\"\n",
    "os.environ[\"MALLOC_ARENA_MAX\"] = \"2\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# 直接按照配置写死参数，避免 Notebook 再次解析 CLI\n",
    "args = Namespace(\n",
    "    ckpt_path=\"/media/bang/backup_omics/pretrained_model/continual_fold2_xenium_hbc1_rep2_2025_05_18_13_43_41/epoch=0-step=122700.ckpt\",\n",
    "    dataset_name=\"xenium_hbc1\",\n",
    "    config=\"/media/dang/Omics/omics/configs/bert_config_5-12.json\",\n",
    "    f=None,\n",
    "    split_slice=None,\n",
    "    target_width=7524,\n",
    "    target_height=5469,\n",
    "    x_min=0,\n",
    "    x_max=7524,\n",
    "    y_min=0,\n",
    "    y_max=5469,\n",
    "    sample_ratio=0.1,\n",
    "    merge_threshold=0.5,\n",
    "    percentile=70,\n",
    "    pca_model_path=\"/media/dang/Omics/omics/visualize/xenium/results_for_sijie2/xenium_hbc1_None_-1_7522_4_5473/xenium_hbc1_None_-1_7522_4_5473_pca.pkl\",\n",
    "    color_model_path=\"/media/dang/Omics/omics/visualize/xenium/results_for_sijie2/xenium_hbc1_None_-1_7522_4_5473/xenium_hbc1_None_-1_7522_4_5473_pca_color.pkl\",\n",
    "    batch_id=0,  # 根据需要修改批次ID (0-9)\n",
    "    total_batches=10\n",
    ")\n",
    "\n",
    "print(f\"Processing batch {args.batch_id + 1}/{args.total_batches}\")\n",
    "print(f\"ckpt_path: {args.ckpt_path}\")\n",
    "print(f\"Dataset: {args.dataset_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12ec228",
   "metadata": {},
   "source": [
    "## Generate visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6e7f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args.radius = 20\n",
    "args.linear_hidden_dim = '256'\n",
    "args.max_points = 20\n",
    "\n",
    "# 加载数据集\n",
    "split_slice = None\n",
    "if args.dataset_name == 'mop1':\n",
    "    adata = pd.read_pickle(MOUSE_SPOT_DATA1) \n",
    "    adata.rename(columns={'target_molecule_name': 'gene', 'cell_index': 'nucleus', 'slice_id': 'batch', 'global_x': 'x', 'global_y': 'y'}, inplace=True)\n",
    "    adata['gene'] = adata['gene'].astype('category')\n",
    "elif args.dataset_name == 'merfish':\n",
    "    adata = pd.read_pickle(MERFISH_DATA1)\n",
    "    split_slice = MERFISH_FOLDS[args.fold]['train']\n",
    "elif args.dataset_name == 'seqfish':\n",
    "    adata = pd.read_pickle(SEQFISH_DATA1)\n",
    "elif args.dataset_name == 'AD_64g_m9721':\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "    adata = pd.read_pickle(AD_64g_9721_DATA)\n",
    "    adata.rename(columns={'slice': 'batch'}, inplace=True)\n",
    "    # if args.fold:\n",
    "    #     split_slice = AD_FOLDS[args.fold]['val']\n",
    "elif args.dataset_name == 'AD_64g_m9781':\n",
    "    adata = pd.read_pickle(AD_64g_9781_DATA)\n",
    "    adata.rename(columns={'slice': 'batch'}, inplace=True)\n",
    "elif args.dataset_name == 'AD_64g_m9919':\n",
    "    adata = pd.read_pickle(AD_64g_9919_DATA)\n",
    "elif args.dataset_name == 'AD_64g_m9930':\n",
    "    adata = pd.read_pickle(AD_64g_9930_DATA)\n",
    "elif args.dataset_name == 'AD_2766g_m9707':\n",
    "    adata = pd.read_pickle(AD_2766g_9707_DATA)\n",
    "elif args.dataset_name == 'AD_2766g_m9735':\n",
    "    adata = pd.read_pickle(AD_2766g_9735_DATA)\n",
    "elif args.dataset_name == 'AD_2766g_m9723':\n",
    "    adata = pd.read_pickle(AD_2766g_9723_DATA)\n",
    "elif args.dataset_name == 'AD_2766g_m9494':\n",
    "    adata = pd.read_pickle(AD_2766g_9494_DATA)\n",
    "elif args.dataset_name == 'AD_2766g_m11346':\n",
    "    adata = pd.read_pickle(AD_2766g_11346_DATA)\n",
    "elif args.dataset_name == 'AD_2766g_m11351':\n",
    "    adata = pd.read_pickle(AD_2766g_11351_DATA)\n",
    "elif args.dataset_name == 'AD_2766g_m9723_2':\n",
    "    adata = pd.read_pickle(AD_2766g_9723_2_DATA)\n",
    "elif args.dataset_name == 'xenium_hbc1':\n",
    "    adata = pd.read_pickle(Xenium_hbc_rep1_DATA)\n",
    "    split_slice = XENIUM_HBC_FOLDS1[args.fold]['train']\n",
    "    split_slice += XENIUM_HBC_FOLDS1[args.fold]['val']\n",
    "elif args.dataset_name == 'xenium_hbc1_rep2':\n",
    "    adata = pd.read_pickle(Xenium_hbc_rep2_DATA)\n",
    "    split_slice = XENIUM_HBC_FOLDS1[args.fold]['train']\n",
    "    split_slice += XENIUM_HBC_FOLDS1[args.fold]['val']\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "# 加载模型\n",
    "print(args.config)\n",
    "model = Omics.load_from_checkpoint(**args.__dict__,checkpoint_path=args.ckpt_path,strict=False)\n",
    "model.eval()\n",
    "model = model.to('cuda')\n",
    "\n",
    "# 数据预处理\n",
    "if args.split_slice:\n",
    "    if args.split_slice.isdigit():\n",
    "        split_slice = [int(args.split_slice)]\n",
    "    else:\n",
    "        split_slice = [args.split_slice]\n",
    "\n",
    "if split_slice:\n",
    "    adata = adata.query(\"batch.isin(@split_slice)\")\n",
    "\n",
    "# 步骤1: 确定分辨率并处理spots\n",
    "total_minx, total_maxx, total_miny, total_maxy = get_min_max_coordinates(adata)\n",
    "scale_x, scale_y, pixel_size_x, pixel_size_y = determine_visualization_resolution(\n",
    "    total_minx, total_maxx, total_miny, total_maxy, args.target_width, args.target_height)\n",
    "\n",
    "# 坐标转换\n",
    "x_min_prop = args.x_min / args.target_width\n",
    "x_max_prop = args.x_max / args.target_width\n",
    "y_min_prop = args.y_min / args.target_height\n",
    "y_max_prop = args.y_max / args.target_height\n",
    "\n",
    "x_range = total_maxx - total_minx\n",
    "y_range = total_maxy - total_miny\n",
    "\n",
    "args.x_min = int(total_minx + (x_min_prop * x_range))\n",
    "args.x_max = int(total_minx + (x_max_prop * x_range))\n",
    "args.y_min = int(total_miny + (y_min_prop * y_range))\n",
    "args.y_max = int(total_miny + (y_max_prop * y_range))\n",
    "\n",
    "# 过滤数据\n",
    "if args.x_min is not None and args.x_max is not None and args.y_min is not None and args.y_max is not None:\n",
    "    adata = adata.query(\"(x >= @args.x_min) & (x <= @args.x_max) & (y >= @args.y_min) & (y <= @args.y_max)\")\n",
    "\n",
    "# 分批处理spots\n",
    "patch_adata = select_batch_spots(adata, args.batch_id, args.total_batches)\n",
    "\n",
    "# 设置label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(adata['gene'].values)\n",
    "annotation_num = patch_adata['gene'].unique().shape[0]\n",
    "\n",
    "# 创建数据加载器\n",
    "val_split = []\n",
    "epoch_callback = EpochCallback()\n",
    "dm = DataModule(SpatialRadiusDataset, my_collate_fn,\n",
    "                data_pct=1.0, batch_size=1000, \n",
    "                num_workers=8, mask_ratio=0, radius=20,\n",
    "                mask_function='random', dataset_name=args.dataset_name,\n",
    "                max_points=20, train_split=split_slice, val_split=val_split,\n",
    "                label_type='pretrain',callback=epoch_callback,\n",
    "                x_min=args.x_min, x_max=args.x_max, y_min=args.y_min, y_max=args.y_max,\n",
    "                adata=patch_adata, batch_id=args.batch_id)\n",
    "dl = dm.inference_train_dataloader()\n",
    "\n",
    "# 提取特征\n",
    "train_rep = get_rep(dl, model)\n",
    "\n",
    "# 创建保存前缀和统计文件路径\n",
    "save_prefix = f\"ficture_vis_results_final/{args.dataset_name}_{args.split_slice}_{args.x_min}_{args.x_max}_{args.y_min}_{args.y_max}\"\n",
    "os.makedirs(\"ficture_vis_results_final\", exist_ok=True)\n",
    "\n",
    "# 统一的统计信息文件路径\n",
    "if args.dataset_name == 'xenium_hbc1_rep2':\n",
    "    stats_file_path = f\"global_stats_xenium_hbc1_p{args.percentile}.json\"\n",
    "else:\n",
    "    stats_file_path = f\"global_stats_{args.dataset_name}_p{args.percentile}.json\"\n",
    "\n",
    "# 步骤2: 生成embedding（使用PCA + 统一的percentile截断和normalize）\n",
    "pca_embeddings, normalized_embeddings, pca_model, pca_color_model = generate_embeddings_with_pca_percentile_clipping(\n",
    "    train_rep, \n",
    "    pca_dim=50, \n",
    "    percentile=args.percentile,\n",
    "    pca_model_path=args.pca_model_path,\n",
    "    color_model_path=args.color_model_path,\n",
    "    save_prefix=save_prefix,\n",
    "    batch_id=args.batch_id,\n",
    "    stats_file_path=stats_file_path  # 新增统计文件路径\n",
    ")\n",
    "\n",
    "# 步骤3: 可视化并保存\n",
    "output_image, coord_color_file = visualize_and_save_embeddings(\n",
    "    total_minx, total_maxx, total_miny, total_maxy,\n",
    "    patch_adata['x'], patch_adata['y'], patch_adata['gene'], patch_adata['cell'],\n",
    "    normalized_embeddings, save_prefix, args.target_width, args.target_height, args.batch_id)\n",
    "\n",
    "# 步骤4: 采样并创建adata\n",
    "final_adata = sample_spots_and_create_adata(\n",
    "    patch_adata, pca_embeddings, normalized_embeddings, \n",
    "    sample_ratio=args.sample_ratio, save_prefix=save_prefix, batch_id=args.batch_id)\n",
    "\n",
    "# 步骤5: 整理结果给思婕\n",
    "results_dir = organize_results_for_delivery(\n",
    "    save_prefix, args.dataset_name, args.split_slice, \n",
    "    args.x_min, args.x_max, args.y_min, args.y_max, args.batch_id)\n",
    "\n",
    "print(f\"\\n=== 处理完成 ===\")\n",
    "print(f\"结果目录: {results_dir}\")\n",
    "print(f\"最终spot数量: {len(patch_adata)}\")\n",
    "print(f\"AnnData形状: {final_adata.shape}\")\n",
    "print(f\"统计信息文件: {stats_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
