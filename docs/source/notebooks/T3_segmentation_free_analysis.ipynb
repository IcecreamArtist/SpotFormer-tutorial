{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c2404bc",
   "metadata": {},
   "source": [
    "# Tutorial 3: Segmentation-free analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abf1c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import argparse\n",
    "import logging\n",
    "from omics.constants import *\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.spatial import cKDTree\n",
    "import scanpy as sc\n",
    "from pytorch_lightning.callbacks import (EarlyStopping, LearningRateMonitor,\n",
    "                                         ModelCheckpoint, Callback)\n",
    "# import squidpy as sq\n",
    "import torch.nn as nn\n",
    "from math import exp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from argparse import Namespace\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from omics.datasets.data_module import testDataModule as DataModule\n",
    "import hashlib\n",
    "import anndata as ad\n",
    "from step1_pretrain import Omics, EpochCallback\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import (EarlyStopping, LearningRateMonitor,\n",
    "                                         ModelCheckpoint)\n",
    "from argparse import ArgumentParser\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import logging\n",
    "import joblib\n",
    "import umap\n",
    "from sklearn.manifold import TSNE\n",
    "import json\n",
    "from visualize import *\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fd7908",
   "metadata": {},
   "source": [
    "## Initialize configs and fix seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb35f44",
   "metadata": {},
   "source": [
    "For efficiency, process all batches and merge them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92682e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# setup environment variables\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# parameters\n",
    "args = Namespace(\n",
    "    ckpt_path=os.path.join(BASE_DIR, 'model_checkpoint.ckpt'),\n",
    "    dataset_name=\"xenium_hbc1\",\n",
    "    config=os.path.join(BASE_DIR, '../../configs/bert_config.json'),\n",
    "    f=None,\n",
    "    split_slice=None,\n",
    "    target_width=7524,\n",
    "    target_height=5469,\n",
    "    x_min=0,\n",
    "    x_max=7524,\n",
    "    y_min=0,\n",
    "    y_max=5469,\n",
    "    sample_ratio=0.1,\n",
    "    merge_threshold=0.5,\n",
    "    percentile=70,\n",
    "    pca_model_path=os.path.join(BASE_DIR, 'xenium_hbc1_None_-1_7524_4_5469_pca.pkl'),\n",
    "    color_model_path=os.path.join(BASE_DIR, 'xenium_hbc1_None_-1_7524_4_5469_pca_color.pkl'),\n",
    "    batch_id=0, # (0-9)\n",
    "    total_batches=10,\n",
    "    radius=20,\n",
    "    linear_hidden_dim='256',\n",
    "    max_points=20,\n",
    "    \n",
    ")\n",
    "\n",
    "print(f\"Processing batch {args.batch_id + 1}/{args.total_batches}\")\n",
    "print(f\"ckpt_path: {args.ckpt_path}\")\n",
    "print(f\"Dataset: {args.dataset_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12ec228",
   "metadata": {},
   "source": [
    "## Specify dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45556b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_slice = None\n",
    "if args.dataset_name == 'mop1':\n",
    "    adata = pd.read_pickle(MOUSE_SPOT_DATA1) \n",
    "    adata.rename(columns={'target_molecule_name': 'gene', 'cell_index': 'nucleus', 'slice_id': 'batch', 'global_x': 'x', 'global_y': 'y'}, inplace=True)\n",
    "    adata['gene'] = adata['gene'].astype('category')\n",
    "elif args.dataset_name == 'merfish':\n",
    "    adata = pd.read_pickle(MERFISH_DATA1)\n",
    "    split_slice = MERFISH_FOLDS[args.fold]['train']\n",
    "elif args.dataset_name == 'seqfish':\n",
    "    adata = pd.read_pickle(SEQFISH_DATA1)\n",
    "elif args.dataset_name == 'AD_64g_m9721':\n",
    "    adata = pd.read_pickle(AD_64g_9721_DATA)\n",
    "    adata.rename(columns={'slice': 'batch'}, inplace=True)\n",
    "elif args.dataset_name == 'AD_64g_m9781':\n",
    "    adata = pd.read_pickle(AD_64g_9781_DATA)\n",
    "    adata.rename(columns={'slice': 'batch'}, inplace=True)\n",
    "elif args.dataset_name == 'AD_64g_m9919':\n",
    "    adata = pd.read_pickle(AD_64g_9919_DATA)\n",
    "elif args.dataset_name == 'AD_64g_m9930':\n",
    "    adata = pd.read_pickle(AD_64g_9930_DATA)\n",
    "elif args.dataset_name == 'AD_2766g_m9707':\n",
    "    adata = pd.read_pickle(AD_2766g_9707_DATA)\n",
    "elif args.dataset_name == 'AD_2766g_m9735':\n",
    "    adata = pd.read_pickle(AD_2766g_9735_DATA)\n",
    "elif args.dataset_name == 'AD_2766g_m9723':\n",
    "    adata = pd.read_pickle(AD_2766g_9723_DATA)\n",
    "elif args.dataset_name == 'AD_2766g_m9494':\n",
    "    adata = pd.read_pickle(AD_2766g_9494_DATA)\n",
    "elif args.dataset_name == 'AD_2766g_m11346':\n",
    "    adata = pd.read_pickle(AD_2766g_11346_DATA)\n",
    "elif args.dataset_name == 'AD_2766g_m11351':\n",
    "    adata = pd.read_pickle(AD_2766g_11351_DATA)\n",
    "elif args.dataset_name == 'AD_2766g_m9723_2':\n",
    "    adata = pd.read_pickle(AD_2766g_9723_2_DATA)\n",
    "elif args.dataset_name == 'xenium_hbc1':\n",
    "    adata = pd.read_pickle(Xenium_hbc_rep1_DATA)\n",
    "    split_slice = XENIUM_HBC_FOLDS1[args.fold]['train']\n",
    "    split_slice += XENIUM_HBC_FOLDS1[args.fold]['val']\n",
    "elif args.dataset_name == 'xenium_hbc1_rep2':\n",
    "    adata = pd.read_pickle(Xenium_hbc_rep2_DATA)\n",
    "    split_slice = XENIUM_HBC_FOLDS1[args.fold]['train']\n",
    "    split_slice += XENIUM_HBC_FOLDS1[args.fold]['val']\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75cbca6",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444607e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "if args.split_slice:\n",
    "    if args.split_slice.isdigit():\n",
    "        split_slice = [int(args.split_slice)]\n",
    "    else:\n",
    "        split_slice = [args.split_slice]\n",
    "\n",
    "if split_slice:\n",
    "    adata = adata.query(\"batch.isin(@split_slice)\")\n",
    "\n",
    "# step1: determine resolution and process spots\n",
    "total_minx, total_maxx, total_miny, total_maxy = get_min_max_coordinates(adata)\n",
    "scale_x, scale_y, pixel_size_x, pixel_size_y = determine_visualization_resolution(\n",
    "    total_minx, total_maxx, total_miny, total_maxy, args.target_width, args.target_height)\n",
    "\n",
    "# coordinate transformation\n",
    "x_min_prop = args.x_min / args.target_width\n",
    "x_max_prop = args.x_max / args.target_width\n",
    "y_min_prop = args.y_min / args.target_height\n",
    "y_max_prop = args.y_max / args.target_height\n",
    "\n",
    "x_range = total_maxx - total_minx\n",
    "y_range = total_maxy - total_miny\n",
    "\n",
    "args.x_min = int(total_minx + (x_min_prop * x_range))\n",
    "args.x_max = int(total_minx + (x_max_prop * x_range))\n",
    "args.y_min = int(total_miny + (y_min_prop * y_range))\n",
    "args.y_max = int(total_miny + (y_max_prop * y_range))\n",
    "\n",
    "# filter data\n",
    "if args.x_min is not None and args.x_max is not None and args.y_min is not None and args.y_max is not None:\n",
    "    adata = adata.query(\"(x >= @args.x_min) & (x <= @args.x_max) & (y >= @args.y_min) & (y <= @args.y_max)\")\n",
    "\n",
    "# process spots in batches\n",
    "patch_adata = select_batch_spots(adata, args.batch_id, args.total_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de12e2ee",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac1e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(adata['gene'].values)\n",
    "annotation_num = patch_adata['gene'].unique().shape[0]\n",
    "\n",
    "# create data loader\n",
    "val_split = []\n",
    "epoch_callback = EpochCallback()\n",
    "dm = DataModule(SpatialRadiusDataset, my_collate_fn,\n",
    "                data_pct=1.0, batch_size=1000, \n",
    "                num_workers=8, mask_ratio=0, radius=20,\n",
    "                mask_function='random', dataset_name=args.dataset_name,\n",
    "                max_points=20, train_split=split_slice, val_split=val_split,\n",
    "                label_type='pretrain',callback=epoch_callback,\n",
    "                x_min=args.x_min, x_max=args.x_max, y_min=args.y_min, y_max=args.y_max,\n",
    "                adata=patch_adata, batch_id=args.batch_id)\n",
    "dl = dm.inference_train_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08f6ba1",
   "metadata": {},
   "source": [
    "## Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14957d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(args.config)\n",
    "model = Omics.load_from_checkpoint(**args.__dict__,checkpoint_path=args.ckpt_path,strict=False)\n",
    "model.eval()\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe66013",
   "metadata": {},
   "source": [
    "## Generating spot embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f722c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rep = get_rep(dl, model)\n",
    "\n",
    "# create save prefix and stats file path\n",
    "save_prefix = f\"vis_results/{args.dataset_name}_{args.split_slice}_{args.x_min}_{args.x_max}_{args.y_min}_{args.y_max}\"\n",
    "os.makedirs(\"vis_results\", exist_ok=True)\n",
    "\n",
    "# unified stats file path\n",
    "stats_file_path = f\"global_stats_{args.dataset_name}_{args.percentile}.json\"\n",
    "\n",
    "# generate embeddings (using PCA + percentile clipping and normalization)\n",
    "pca_embeddings, normalized_embeddings, pca_model, pca_color_model = generate_embeddings_with_pca_percentile_clipping(\n",
    "    train_rep, \n",
    "    pca_dim=50, \n",
    "    percentile=args.percentile,\n",
    "    pca_model_path=args.pca_model_path,\n",
    "    color_model_path=args.color_model_path,\n",
    "    save_prefix=save_prefix,\n",
    "    batch_id=args.batch_id,\n",
    "    stats_file_path=stats_file_path \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3594c7",
   "metadata": {},
   "source": [
    "## Visualization generation and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a678b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize and save embeddings\n",
    "output_image, coord_color_file = visualize_and_save_embeddings(\n",
    "    total_minx, total_maxx, total_miny, total_maxy,\n",
    "    patch_adata['x'], patch_adata['y'], patch_adata['gene'], patch_adata['cell'],\n",
    "    normalized_embeddings, save_prefix, args.target_width, args.target_height, args.batch_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7734a4f0",
   "metadata": {},
   "source": [
    "## Generating adata with colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcd7bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample and create adata\n",
    "final_adata = sample_spots_and_create_adata(\n",
    "    patch_adata, pca_embeddings, normalized_embeddings, \n",
    "    sample_ratio=args.sample_ratio, save_prefix=save_prefix, batch_id=args.batch_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889aa77d",
   "metadata": {},
   "source": [
    "## Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f5455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step5: organize results for delivery\n",
    "results_dir = organize_results_for_delivery(\n",
    "    save_prefix, args.dataset_name, args.split_slice, \n",
    "    args.x_min, args.x_max, args.y_min, args.y_max, args.batch_id)\n",
    "\n",
    "print(f\"\\n=== Finished ===\")\n",
    "print(f\"Results directory: {results_dir}\")\n",
    "print(f\"Final spot number: {len(patch_adata)}\")\n",
    "print(f\"AnnData shape: {final_adata.shape}\")\n",
    "print(f\"Stats file: {stats_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
