{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "808f6772",
   "metadata": {},
   "source": [
    "# Tutorial 6: Generate context-aware cell embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfad740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "import pickle\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import defaultdict, OrderedDict\n",
    "from tqdm import tqdm\n",
    "from argparse import Namespace\n",
    "import gc\n",
    "\n",
    "from omics.constants import *\n",
    "import os\n",
    "import torch.utils.data as data\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from omics.constants import *\n",
    "import h5py\n",
    "from pytorch_lightning.callbacks import (EarlyStopping, LearningRateMonitor,\n",
    "                                         ModelCheckpoint, Callback)\n",
    "from math import exp\n",
    "import random\n",
    "import h5py\n",
    "import hashlib\n",
    "import anndata as ad\n",
    "from omics.Pretrain.omics.pretrain_fold2 import Omics\n",
    "# from omics.Finetune.finetune_fold import Omics\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "from argparse import ArgumentParser\n",
    "from collections import defaultdict\n",
    "from scipy.spatial import cKDTree\n",
    "from step0_spot_input_gen import load_spot_data_with_full_info\n",
    "from step2_uncond_cell_emb_gen import run_multi_gpu_processing_with_filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545acb1b",
   "metadata": {},
   "source": [
    "## Initialize args and fix seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb5a117",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "args = Namespace(\n",
    "    ckpt_path=\"SpotFormer_checkpoint.ckpt\",\n",
    "    dataset_name=\"mop1_filtered\",\n",
    "    target_dataset=\"mop1_filtered\",\n",
    "    gene_pct=100,\n",
    "    use_multi_gpu=True,\n",
    "    num_gpus=2,\n",
    "    radius=20,  \n",
    "    max_points=20,\n",
    "    linear_hidden_dim='256', \n",
    "    config=\"configs/bert_config.json\", \n",
    "    seed=42,\n",
    "    f=None,\n",
    "    split_slice=None,\n",
    "    target_width=6724,\n",
    "    target_height=5885,\n",
    "    x_min=None,\n",
    "    x_max=None,\n",
    "    y_min=None,\n",
    "    y_max=None,\n",
    "    sample_ratio=1.0,\n",
    "    merge_threshold=0.5,\n",
    "    percentile=70\n",
    ")\n",
    "\n",
    "print('ckpt_path:', args.ckpt_path)\n",
    "print(f\"Dataset: {args.dataset_name}, gene_pct: {args.gene_pct}\")\n",
    "print(f\"Use multi-GPU: {args.use_multi_gpu}, num_gpus: {args.num_gpus}\")\n",
    "\n",
    "seed_everything(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101c5bab",
   "metadata": {},
   "source": [
    "## Generate unconditional cell embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398c6d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_h5_path = f'cached_spot_data/spot_input_spot_all_{args.dataset_name}_{args.seed}_{args.gene_pct}_{args.radius}_{args.max_points}.h5'\n",
    "\n",
    "if args.use_multi_gpu:\n",
    "    print(\"Using Multi-GPU processing with H5 split\")\n",
    "    cell_embeddings = run_multi_gpu_processing_with_filtered_data(args, global_h5_path, num_gpus=args.num_gpus)\n",
    "else:\n",
    "    print(\"Single-GPU processing not implemented for filtered data yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d4cc61",
   "metadata": {},
   "source": [
    "## Task: missing gene imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6df433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import datetime\n",
    "import os\n",
    "import torch\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import (EarlyStopping, LearningRateMonitor,\n",
    "                                         ModelCheckpoint)\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from dateutil import tz\n",
    "\n",
    "from missing_gene_imputation.gimVI import OptimizedFixedReferenceBasedGimVI, optimize_dataloader_args\n",
    "from omics.datasets.cell_dataset6 import QueRefCellDataModule\n",
    "\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922332e3",
   "metadata": {},
   "source": [
    "### Initialize arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127532ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define arguments directly\n",
    "args = Namespace(\n",
    "    # Model dimensions (will be updated from data)\n",
    "    embedding_dim=768,\n",
    "    n_available_genes=2000,\n",
    "    n_target_genes=1000,\n",
    "    spatial_dim=2,\n",
    "    \n",
    "    # Reference-based parameters\n",
    "    latent_dim=256,\n",
    "    reference_latent_dim=256,\n",
    "    similarity_metric=\"cosine\",  # \"cosine\", \"learned\", \"l2\"\n",
    "    temperature=0.1,\n",
    "    top_k_references=50,\n",
    "    \n",
    "    # Input modality selection (only one should be True)\n",
    "    use_gene_expression=True,\n",
    "    use_cell_embedding=False,\n",
    "    \n",
    "    # Output activation strategy\n",
    "    output_activation=\"softplus\",  # \"relu\", \"softplus\", \"exp\", \"sigmoid\"\n",
    "    use_batch_norm_output=True,\n",
    "    min_expression_value=1e-6,\n",
    "    \n",
    "    # Loss function improvements\n",
    "    loss_function=\"mse\",  # \"mse\", \"poisson\", \"nb\", \"rmse\"\n",
    "    use_log_space_loss=False,\n",
    "    expression_scale_factor=1.0,\n",
    "    \n",
    "    # Decoder parameters\n",
    "    hidden_dim=256,\n",
    "    dropout=0.1,\n",
    "    use_spatial_decoder=True,\n",
    "    \n",
    "    # Training strategy\n",
    "    reconstruction_weight=1.0,\n",
    "    similarity_weight=0.5,\n",
    "    consistency_weight=0.1,\n",
    "    \n",
    "    # Reference processing\n",
    "    reference_sampling_ratio=1.0,\n",
    "    reference_clustering=True,\n",
    "    n_reference_clusters=200,\n",
    "    \n",
    "    # Training parameters\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=0.01,\n",
    "    warmup_epochs=10,\n",
    "    batch_size=128,\n",
    "    epochs=100,\n",
    "    num_workers=8,\n",
    "    \n",
    "    # Optimization parameters\n",
    "    metric_compute_frequency=20,\n",
    "    val_metric_compute_frequency=5,\n",
    "    memory_cleanup_frequency=200,\n",
    "    log_frequency=10,\n",
    "    enable_fast_loss=True,\n",
    "    \n",
    "    # Data parameters\n",
    "    normalize_embeddings=True,\n",
    "    log_transform_counts=True,\n",
    "    pin_memory=False,\n",
    "    reference_ratio=0.7,\n",
    "    reference_split_seed=42,\n",
    "    \n",
    "    # Evaluation parameters\n",
    "    evaluation_output_dir=\"./optimized_reference_gimvi_evaluation\",\n",
    "    save_detailed_reports=True,\n",
    "    save_anndata=True,\n",
    "    compute_gene_level_metrics=True,\n",
    "    \n",
    "    # Experiment settings\n",
    "    experiment_name=\"optimized_reference_based_gimvi\",\n",
    "    seed=42,\n",
    "    dataset_name=\"mop1_filtered\",  # \"mop1_filtered\", \"seqfish\", \"AD_9494_9498\"\n",
    "    dataset_name2=None,\n",
    "    fold=\"fold_1\",\n",
    "    data_pct=50,\n",
    "    mode=\"test\",  # \"test\" or \"train_test\"\n",
    "    \n",
    "    # Checkpoint\n",
    "    ckpt_path=None,\n",
    "    \n",
    "    # Trainer settings\n",
    "    accelerator=None,\n",
    "    devices=None,\n",
    "    deterministic=False,\n",
    "    precision=32,\n",
    "    gradient_clip_val=1.0,\n",
    "    enable_progress_bar=True,\n",
    "    enable_model_summary=False,\n",
    "    sync_batchnorm=False,\n",
    "    detect_anomaly=False,\n",
    ")\n",
    "\n",
    "# Update max_epochs\n",
    "args.max_epochs = args.epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413668aa",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c365a24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply dataloader optimizations\n",
    "print(\"Applying dataloader optimizations...\")\n",
    "args = optimize_dataloader_args(args)\n",
    "\n",
    "\n",
    "# Data paths\n",
    "if args.dataset_name == 'mop1_filtered':\n",
    "    adata_path = f'cell_embeddings/processed_adata_mop1_filtered_42_{args.data_pct}.h5ad'\n",
    "    adata_path2 = None\n",
    "elif args.dataset_name == 'seqfish':\n",
    "    adata_path = f'cell_embeddings/processed_adata_{args.dataset_name}_{args.seed}_{args.data_pct}.h5ad'\n",
    "    adata_path2 = None\n",
    "elif args.dataset_name == 'AD_9494_9498':\n",
    "    adata_path = f'cell_embeddings/9494_adata_{args.data_pct}pct.h5ad'\n",
    "    adata_path2 = f'cell_embeddings/9498_adata_{args.data_pct}pct.h5ad'\n",
    "\n",
    "# Data module\n",
    "datamodule = QueRefCellDataModule(\n",
    "    adata_path=adata_path,\n",
    "    adata_path2=adata_path2,\n",
    "    fold_name=args.fold,\n",
    "    batch_size=args.batch_size,\n",
    "    num_workers=args.num_workers,\n",
    "    normalize_embeddings=args.normalize_embeddings,\n",
    "    log_transform_counts=args.log_transform_counts,\n",
    "    pin_memory=args.pin_memory,\n",
    "    reference_ratio=args.reference_ratio,\n",
    "    k_neighbors=50,\n",
    "    reference_split_seed=args.reference_split_seed\n",
    ")\n",
    "\n",
    "# Setup data module\n",
    "datamodule.setup()\n",
    "datamodule.dataset_name = args.dataset_name\n",
    "datamodule.seed = args.seed\n",
    "datamodule.data_pct = args.data_pct\n",
    "\n",
    "# Get data dimensions\n",
    "dims = datamodule.get_dimensions()\n",
    "\n",
    "# Update model parameters\n",
    "args.embedding_dim = dims['embedding_dim']\n",
    "args.n_available_genes = dims['n_available_genes']\n",
    "args.n_target_genes = dims['n_target_genes']\n",
    "args.spatial_dim = dims['spatial_dim']\n",
    "\n",
    "print(f\"Optimized Reference gimVI dimensions:\")\n",
    "print(f\"  embedding_dim: {args.embedding_dim}\")\n",
    "print(f\"  n_available_genes: {args.n_available_genes}\")\n",
    "print(f\"  n_target_genes: {args.n_target_genes}\")\n",
    "print(f\"Optimization parameters:\")\n",
    "print(f\"  Train metric frequency: {args.metric_compute_frequency}\")\n",
    "print(f\"  Val metric frequency: {args.val_metric_compute_frequency}\")\n",
    "print(f\"  Memory cleanup frequency: {args.memory_cleanup_frequency}\")\n",
    "print(f\"  Log frequency: {args.log_frequency}\")\n",
    "print(f\"  Fast loss: {args.enable_fast_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d559967",
   "metadata": {},
   "source": [
    "### Configure model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702b83c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update max_epochs\n",
    "args.max_epochs = args.epochs\n",
    "\n",
    "# GPU Configuration\n",
    "print(\"=== GPU Configuration ===\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name()}\")\n",
    "    \n",
    "    if args.accelerator is None:\n",
    "        args.accelerator = \"gpu\"\n",
    "    if args.devices is None:\n",
    "        args.devices = 1\n",
    "        \n",
    "    print(f\"Trainer will use: accelerator={args.accelerator}, devices={args.devices}\")\n",
    "else:\n",
    "    print(\"CUDA not available, using CPU\")\n",
    "    args.accelerator = \"cpu\"\n",
    "    args.devices = 1\n",
    "print(\"========================\")\n",
    "\n",
    "# Set random seed\n",
    "seed_everything(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6daa279",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab372fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup callbacks and logger\n",
    "now = datetime.datetime.now(tz.tzlocal())\n",
    "extension = now.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "ckpt_dir = os.path.join(\n",
    "    BASE_DIR, f\"../../../data/ckpts/optimized_reference_gimvi/{args.experiment_name}_{args.dataset_name}_{extension}\")\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "# Fixed callbacks - use val_loss instead of val_pearson as primary monitoring metric\n",
    "callbacks = [\n",
    "    LearningRateMonitor(logging_interval=\"step\"),\n",
    "    ModelCheckpoint(\n",
    "        monitor=\"val_loss\",  # Changed to val_loss for better stability\n",
    "        dirpath=ckpt_dir,\n",
    "        save_last=True, \n",
    "        mode=\"min\",  # Changed to min mode\n",
    "        save_top_k=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_loss\",  # Changed to val_loss\n",
    "        min_delta=0.001,\n",
    "        patience=20,\n",
    "        verbose=False, \n",
    "        mode=\"min\"  # Changed to min mode\n",
    "    )\n",
    "]\n",
    "\n",
    "logger_dir = os.path.join(BASE_DIR, f\"../../../data\")\n",
    "os.makedirs(logger_dir, exist_ok=True)\n",
    "wandb_logger = WandbLogger(\n",
    "    project=f\"Optimized_Reference_Based_gimVI\", \n",
    "    save_dir=logger_dir, \n",
    "    name=f\"{args.experiment_name}_{args.dataset_name}_{args.data_pct}_{args.fold}_{extension}\"\n",
    ")\n",
    "\n",
    "# Optimized trainer configuration\n",
    "trainer = Trainer(\n",
    "    accelerator=args.accelerator,\n",
    "    devices=args.devices,\n",
    "    max_epochs=args.max_epochs,\n",
    "    deterministic=args.deterministic,\n",
    "    callbacks=callbacks,\n",
    "    logger=wandb_logger,\n",
    "    precision=args.precision,\n",
    "    gradient_clip_val=args.gradient_clip_val,\n",
    "    enable_progress_bar=args.enable_progress_bar,\n",
    "    log_every_n_steps=args.log_frequency * 5,  # Reduced logging frequency\n",
    "    enable_model_summary=args.enable_model_summary,\n",
    "    sync_batchnorm=args.sync_batchnorm,\n",
    "    detect_anomaly=args.detect_anomaly,\n",
    ")\n",
    "\n",
    "# Set trainer metadata\n",
    "trainer.dataset_name = args.dataset_name\n",
    "trainer.seed = args.seed\n",
    "trainer.data_pct = args.data_pct\n",
    "\n",
    "# Save checkpoint flag\n",
    "is_save_ckpt = True\n",
    "\n",
    "if args.mode == \"train_test\":\n",
    "    # Training\n",
    "    print(\"Training Optimized Reference-based gimVI...\")\n",
    "    trainer.fit(model, datamodule=datamodule)\n",
    "    \n",
    "    if is_save_ckpt:\n",
    "        best_ckpt_path = os.path.join(ckpt_dir, \"best_ckpts.yaml\")\n",
    "        callbacks[1].to_yaml(filepath=best_ckpt_path)\n",
    "    \n",
    "    # Load best model for testing\n",
    "    args.ckpt_path = callbacks[1].best_model_path\n",
    "    if args.ckpt_path:\n",
    "        model = OptimizedFixedReferenceBasedGimVI.load_from_checkpoint(args.ckpt_path, **vars(args))\n",
    "\n",
    "# Testing\n",
    "print(\"Testing Optimized Reference-based gimVI...\")\n",
    "test_results = trainer.test(model, datamodule=datamodule)\n",
    "print(\"Optimized Reference-based gimVI experiment completed!\")\n",
    "print(f\"Test results: {test_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939a2087",
   "metadata": {},
   "source": [
    "## Task: cell type classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e19882",
   "metadata": {},
   "source": [
    "### Initialize arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fdec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cell_type_classification.cellplm import *\n",
    "from argparse import Namespace\n",
    "\n",
    "# Define arguments directly\n",
    "args = Namespace(\n",
    "    # Pretrain settings\n",
    "    pretrain_version='20230926_85M',\n",
    "    pretrain_directory='ckpts/CellPLM',\n",
    "    \n",
    "    # Data and environment\n",
    "    dataset_name='mop1_filtered',  # Required\n",
    "    dataset_name2=None,\n",
    "    fold='fold_1',\n",
    "    data_pct=50,  # Required\n",
    "    seed=42,\n",
    "    label_type='class',  # 'class' or 'subclass'\n",
    "    \n",
    "    # Logging and saving\n",
    "    evaluation_dir='./cellplm_evaluation',\n",
    "    save_detailed_reports=True,  # Required\n",
    "    save_anndata=True,  # Required\n",
    "    compute_gene_level_metrics=True,  # Required\n",
    "    \n",
    "    # Mode control\n",
    "    mode='test',  # 'test' or 'train_test'\n",
    "    \n",
    "    # Fusion related parameters\n",
    "    enable_fusion=True,\n",
    "    fusion_type='concat',  # 'concat', 'add', 'gated', 'attention'\n",
    "    fusion_dropout=0.2,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54ea331",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3c1261",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset_name == 'mop1_filtered':\n",
    "    data_path = f'/media/dang/Omics/omics/baseline/imputation/cell_embeddings_with_GT/processed_adata_mop1_filtered_42_{args.data_pct}.h5ad'\n",
    "    data_path2 = None\n",
    "else:\n",
    "    data_path = f'/media/dang/Omics/omics/baseline/annotation/cell_embeddings_with_GT/processed_adata_{args.dataset_name}_{args.seed}_{args.data_pct}.h5ad'\n",
    "    data_path2 = f'/media/dang/Omics/omics/baseline/annotation/cell_embeddings_with_GT/processed_adata_{args.dataset_name2}_{args.seed}_{args.data_pct}.h5ad'\n",
    "\n",
    "# Load downstream dataset\n",
    "data = load_data(data_path, data_path2, args.label_type, args.fold, args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aef292",
   "metadata": {},
   "source": [
    "### Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccde5f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite parts of the default config\n",
    "pipeline_config = CellTypeAnnotationDefaultPipelineConfig.copy()\n",
    "\n",
    "model_config = CellTypeAnnotationDefaultModelConfig.copy()\n",
    "model_config['out_dim'] = data.obs['celltype'].nunique()\n",
    "\n",
    "# Fine-tuning the model (freeze encoder, only train decoder)\n",
    "pipeline_config = CellTypeAnnotationDefaultPipelineConfig.copy()\n",
    "\n",
    "model_config = CellTypeAnnotationDefaultModelConfig.copy()\n",
    "model_config['out_dim'] = data.obs['celltype'].nunique()\n",
    "pipeline_config, model_config\n",
    "\n",
    "model_config['enable_cell_embedding'] = True\n",
    "model_config['post_latent_dim'] = 768\n",
    "model_config['enable_fusion'] = args.enable_fusion\n",
    "model_config['fusion_type'] = args.fusion_type\n",
    "model_config['fusion_dropout'] = args.fusion_dropout\n",
    "model_config['enc_hid'] = 217 if args.dataset_name == 'mop1_filtered' else 1000\n",
    "\n",
    "pipeline = CellTypeAnnotationPipeline(pretrain_prefix=args.pretrain_version,  # Specify the pretrain checkpoint to load\n",
    "                                    overwrite_config=model_config,  # This is for overwriting part of the pretrain config\n",
    "                                    pretrain_directory=args.pretrain_directory)\n",
    "pipeline.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b5b392",
   "metadata": {},
   "source": [
    "### Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e526131",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.mode == 'train_test':\n",
    "    pipeline.fit(data,  # An AnnData object\n",
    "            pipeline_config,  # The config dictionary we created previously, optional\n",
    "            split_field='split',  # Specify a column in .obs that contains split information\n",
    "            train_split='train',\n",
    "            valid_split='valid',\n",
    "            label_fields=['celltype'],  # Specify a column in .obs that contains cell type labels\n",
    "            enable_fusion=args.enable_fusion)  # Enable fusion functionality\n",
    "\n",
    "# Inference and evaluation\n",
    "if args.mode == 'test':\n",
    "    pipeline.fitted = True  # Although it doesn't support not fitted, we can force set to True since checkpoint is loaded\n",
    "\n",
    "pipeline.predict(\n",
    "                data,  # An AnnData object\n",
    "                pipeline_config,  # The config dictionary we created previously, optional\n",
    "                label_fields=['celltype'],\n",
    "                enable_fusion=args.enable_fusion  # Enable fusion functionality\n",
    "            )\n",
    "\n",
    "scores = pipeline.score(data,  # An AnnData object\n",
    "            pipeline_config,  # The config dictionary we created previously, optional\n",
    "            split_field='split',  # Specify a column in .obs to specify train and valid split, optional\n",
    "            target_split='test',  # Specify a target split to predict, optional\n",
    "            label_fields=['celltype'],  # Specify a column in .obs that contains cell type labels\n",
    "            dataset_name=args.dataset_name,\n",
    "            fold_name=args.fold,\n",
    "            data_pct=args.data_pct,\n",
    "            seed=args.seed,\n",
    "            label_type=args.label_type,\n",
    "            evaluation_output_dir=args.evaluation_dir,\n",
    "            save_detailed_reports=args.save_detailed_reports,\n",
    "            save_anndata=args.save_anndata)  \n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84aa9b2",
   "metadata": {},
   "source": [
    "### AUC evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdebf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['savefig.dpi'] = 300 \n",
    "plt.rcParams['figure.dpi'] = 300 \n",
    "\n",
    "import scipy.stats as stats\n",
    "import mpl_toolkits.axisartist as axisartist\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import scanpy as sc\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "baseline_path = \"cellplm_evaluation/cellPLM_mop1_filtered_fold_1_42_20250819_215447_50_subclass.h5ad\"\n",
    "enhanced_path = \"cellplm_enhanced_evaluation/cellPLM_mop1_filtered_fold_1_42_20250825_000654_50_subclass.h5ad\"\n",
    "\n",
    "from cell_type_classification.eval import calculate_auc_comparison\n",
    "\n",
    "print(\"ðŸš€ Start calculating AUC...\")\n",
    "auc_df = calculate_auc_comparison(baseline_path, enhanced_path)\n",
    "\n",
    "print(\"\\nâœ… AUC calculation completed!\")\n",
    "print(\"ðŸ“ Generated file: auc_results.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e514fe00",
   "metadata": {},
   "source": [
    "### Figure generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc11e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from cell_type_classification.fig_gen import create_heatmaps_single_cell_confidence_seaborn\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 10,\n",
    "    'axes.labelsize': 12,\n",
    "    'axes.titlesize': 14,\n",
    "    'legend.fontsize': 9,\n",
    "    'figure.dpi': 100\n",
    "})\n",
    "\n",
    "baseline_path = \"cellplm_evaluation/cellPLM_mop1_filtered_fold_1_42_20250819_215447_50_subclass.h5ad\"\n",
    "enhanced_path = \"cellplm_enhanced_evaluation/cellPLM_mop1_filtered_fold_1_42_20250825_000654_50_subclass.h5ad\"\n",
    "\n",
    "print(\"Starting single-cell confidence heatmap generation (using seaborn template)...\")\n",
    "baseline_fig, enhanced_fig = create_heatmaps_single_cell_confidence_seaborn(\n",
    "    baseline_path, enhanced_path, max_cells=2000\n",
    ")\n",
    "\n",
    "print(\"\\nAll single-cell confidence heatmap generation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abcef05",
   "metadata": {},
   "source": [
    "## Generate conditional cell embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ac65b9",
   "metadata": {},
   "source": [
    "### match spot embeddings into cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb73c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from step3_cell_matching import match_cells_by_coordinates\n",
    "args = Namespace(\n",
    "    dataset_id=\"9494\",\n",
    "    output_dir=\"AD_cell_embeddings\",\n",
    "    data_name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7887f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_path = f'AD/2022-09-16-Hu-AD-stardist-scaled.h5ad'\n",
    "\n",
    "print(\"=== Reading Cell Embeddings AnnData ===\")\n",
    "\n",
    "# Load file\n",
    "adata_cells = ad.read_h5ad(adata_path)\n",
    "\n",
    "adata_9494 = adata_cells[adata_cells.obs['sample'] == f'ADmouse_{args.dataset_id}']\n",
    "\n",
    "# Read cell embeddings AnnData file\n",
    "adata_emb_path = f'spot_input_spot_all_AD_2766g_m{args.dataset_id}_42_100_20_20{args.data_name}_cells.h5ad'\n",
    "\n",
    "# Load file\n",
    "adata_emb = ad.read_h5ad(adata_emb_path)\n",
    "\n",
    "# Usage example\n",
    "matched_adata = match_cells_by_coordinates(adata_9494, adata_emb, tolerance=20)\n",
    "\n",
    "# Ensure correct data types for all string columns before saving\n",
    "matched_adata.obs['cell_orig_id'] = matched_adata.obs['cell_orig_id'].astype(str)\n",
    "matched_adata.obs['cell_total_id'] = matched_adata.obs['cell_total_id'].astype(str)\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "# Save matching results\n",
    "matched_adata.write_h5ad(f'{args.output_dir}/AD_cell_matching_m{args.dataset_id}{args.data_name}.h5ad')\n",
    "\n",
    "# View matching results\n",
    "matched_count = (matched_adata.obs['cell_orig_id'] != 'unmatched').sum()\n",
    "print(f\"Successfully matched cells: {matched_count}\")\n",
    "print(f\"Total cells: {len(matched_adata.obs)}\")\n",
    "print(f\"Matching rate: {matched_count / len(matched_adata.obs):.2%}\")\n",
    "print(\"\\nMatching results example:\")\n",
    "print(matched_adata.obs[['center_x', 'center_y', 'cell_orig_id', 'cell_total_id']].head())\n",
    "\n",
    "# View successfully matched cells\n",
    "matched_cells = matched_adata.obs[matched_adata.obs['cell_orig_id'] != 'unmatched']\n",
    "if len(matched_cells) > 0:\n",
    "    print(\"\\nSuccessfully matched cells example:\")\n",
    "    print(matched_cells[['center_x', 'center_y', 'cell_orig_id', 'cell_total_id']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfb823a",
   "metadata": {},
   "source": [
    "### Train conditional aggregation and cell embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f8b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from step4_cond_cell_emb_gen import run_train_and_cell_emb_gen\n",
    "\n",
    "run_train_and_cell_emb_gen()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
