{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e6ae0ef",
   "metadata": {},
   "source": [
    "# Tutorial 8: Gene imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2298c014",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ğŸš€ ä¿®å¤çš„ä¸»è®­ç»ƒå‡½æ•°\"\"\"\n",
    "parser = ArgumentParser()\n",
    "parser = Trainer.add_argparse_args(parser)\n",
    "parser = OptimizedFixedReferenceBasedGimVI.add_model_specific_args(parser)\n",
    "parser.add_argument(\"--ckpt_path\", type=str, default=None)\n",
    "\n",
    "args = parser.parse_args()\n",
    "args.deterministic = False\n",
    "args.max_epochs = args.epochs\n",
    "\n",
    "# GPUé…ç½®\n",
    "print(\"=== GPU Configuration ===\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name()}\")\n",
    "    \n",
    "    if not hasattr(args, 'accelerator') or args.accelerator is None:\n",
    "        args.accelerator = \"gpu\"\n",
    "    if not hasattr(args, 'devices') or args.devices is None:\n",
    "        args.devices = 1\n",
    "        \n",
    "    print(f\"Trainer will use: accelerator={args.accelerator}, devices={args.devices}\")\n",
    "else:\n",
    "    print(\"CUDA not available, using CPU\")\n",
    "    args.accelerator = \"cpu\"\n",
    "    args.devices = 1\n",
    "print(\"========================\")\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "seed_everything(args.seed)\n",
    "\n",
    "# åº”ç”¨dataloaderä¼˜åŒ–\n",
    "print(\"ğŸ”§ Applying dataloader optimizations...\")\n",
    "args = optimize_dataloader_args(args)\n",
    "\n",
    "# æ•°æ®è·¯å¾„\n",
    "if args.dataset_name == 'mop1_filtered':\n",
    "    adata_path = f'/media/dang/Omics/omics/baseline/imputation/cell_embeddings_with_GT/processed_adata_mop1_filtered_42_{args.data_pct}.h5ad'\n",
    "    adata_path2 = None\n",
    "elif args.dataset_name == 'seqfish':\n",
    "    adata_path = f'/media/dang/Omics/omics/baseline/imputation/cell_embeddings_with_GT/processed_adata_{args.dataset_name}_{args.seed}_{args.data_pct}.h5ad'\n",
    "    adata_path2 = None\n",
    "elif args.dataset_name == 'AD_9494_9498':\n",
    "    adata_path = f'/media/dang/Omics/omics/baseline/imputation/AD_cell_embeddings_pct/9494_adata_{args.data_pct}pct.h5ad'\n",
    "    adata_path2 = f'/media/dang/Omics/omics/baseline/imputation/AD_cell_embeddings_pct/9498_adata_{args.data_pct}pct.h5ad'\n",
    "\n",
    "# æ•°æ®æ¨¡å—\n",
    "datamodule = QueRefCellDataModule(\n",
    "    adata_path=adata_path,\n",
    "    adata_path2=adata_path2,\n",
    "    fold_name=args.fold,\n",
    "    batch_size=args.batch_size,\n",
    "    num_workers=args.num_workers,\n",
    "    normalize_embeddings=args.normalize_embeddings,\n",
    "    log_transform_counts=args.log_transform_counts,\n",
    "    pin_memory=args.pin_memory,\n",
    "    reference_ratio=args.reference_ratio,\n",
    "    k_neighbors=50,\n",
    "    reference_split_seed=args.reference_split_seed\n",
    ")\n",
    "\n",
    "# è®¾ç½®æ•°æ®æ¨¡å—\n",
    "datamodule.setup()\n",
    "datamodule.dataset_name = args.dataset_name\n",
    "datamodule.seed = args.seed\n",
    "datamodule.data_pct = args.data_pct\n",
    "\n",
    "# è·å–æ•°æ®ç»´åº¦\n",
    "dims = datamodule.get_dimensions()\n",
    "\n",
    "# æ›´æ–°æ¨¡å‹å‚æ•°\n",
    "args.embedding_dim = dims['embedding_dim']\n",
    "args.n_available_genes = dims['n_available_genes']\n",
    "args.n_target_genes = dims['n_target_genes']\n",
    "args.spatial_dim = dims['spatial_dim']\n",
    "\n",
    "print(f\"ğŸ“ Optimized Reference gimVI dimensions:\")\n",
    "print(f\"  embedding_dim: {args.embedding_dim}\")\n",
    "print(f\"  n_available_genes: {args.n_available_genes}\")\n",
    "print(f\"  n_target_genes: {args.n_target_genes}\")\n",
    "print(f\"ğŸš€ Optimization parameters:\")\n",
    "print(f\"  Train metric frequency: {args.metric_compute_frequency}\")\n",
    "print(f\"  Val metric frequency: {args.val_metric_compute_frequency}\")\n",
    "print(f\"  Memory cleanup frequency: {args.memory_cleanup_frequency}\")\n",
    "print(f\"  Log frequency: {args.log_frequency}\")\n",
    "print(f\"  Fast loss: {args.enable_fast_loss}\")\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹\n",
    "if args.ckpt_path:\n",
    "    model = OptimizedFixedReferenceBasedGimVI.load_from_checkpoint(args.ckpt_path, **args.__dict__)\n",
    "else:\n",
    "    model = OptimizedFixedReferenceBasedGimVI(**args.__dict__)\n",
    "\n",
    "# è®¾ç½®callbackså’Œlogger\n",
    "now = datetime.datetime.now(tz.tzlocal())\n",
    "extension = now.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "ckpt_dir = os.path.join(\n",
    "    BASE_DIR, f\"../../../data/ckpts/optimized_reference_gimvi/{args.experiment_name}_{args.dataset_name}_{extension}\")\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "# ğŸ”¥ ä¿®å¤callbacks - ä½¿ç”¨val_lossè€Œä¸æ˜¯val_pearsonä½œä¸ºä¸»è¦ç›‘æ§æŒ‡æ ‡\n",
    "callbacks = [\n",
    "    LearningRateMonitor(logging_interval=\"step\"),\n",
    "    ModelCheckpoint(\n",
    "        monitor=\"val_loss\",  # æ”¹ä¸ºval_lossï¼Œæ›´ç¨³å®š\n",
    "        dirpath=ckpt_dir,\n",
    "        save_last=True, \n",
    "        mode=\"min\",  # æ”¹ä¸ºminæ¨¡å¼\n",
    "        save_top_k=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_loss\",  # æ”¹ä¸ºval_loss\n",
    "        min_delta=0.001,\n",
    "        patience=20,\n",
    "        verbose=False, \n",
    "        mode=\"min\"  # æ”¹ä¸ºminæ¨¡å¼\n",
    "    )\n",
    "]\n",
    "\n",
    "logger_dir = os.path.join(BASE_DIR, f\"../../../data\")\n",
    "os.makedirs(logger_dir, exist_ok=True)\n",
    "wandb_logger = WandbLogger(\n",
    "    project=f\"Optimized_Reference_Based_gimVI\", \n",
    "    save_dir=logger_dir, \n",
    "    name=f\"{args.experiment_name}_{args.dataset_name}_{args.data_pct}_{args.fold}_{extension}\"\n",
    ")\n",
    "\n",
    "# ä¼˜åŒ–çš„traineré…ç½®\n",
    "trainer = Trainer.from_argparse_args(\n",
    "    args=args,\n",
    "    deterministic=False,\n",
    "    callbacks=callbacks,\n",
    "    logger=wandb_logger,\n",
    "    precision=32,\n",
    "    gradient_clip_val=1.0,\n",
    "    # æ·»åŠ è¿™äº›ä¼˜åŒ–å‚æ•°\n",
    "    enable_progress_bar=True,\n",
    "    log_every_n_steps=args.log_frequency * 5,  # å‡å°‘loggingé¢‘ç‡\n",
    "    # flush_logs_every_n_steps=args.log_frequency * 10,  # å‡å°‘logåˆ·æ–°é¢‘ç‡\n",
    "    enable_model_summary=False,  # ç¦ç”¨æ¨¡å‹æ‘˜è¦\n",
    "    sync_batchnorm=False,  # å¦‚æœå•GPUï¼Œç¦ç”¨åŒæ­¥BN\n",
    "    detect_anomaly=False,  # ç¦ç”¨anomaly detection\n",
    ")\n",
    "\n",
    "# è®¾ç½®trainerçš„å…ƒæ•°æ®\n",
    "trainer.dataset_name = args.dataset_name\n",
    "trainer.seed = args.seed\n",
    "trainer.data_pct = args.data_pct\n",
    "\n",
    "if args.mode == \"train_test\":\n",
    "    # è®­ç»ƒ\n",
    "    print(\"ğŸ§‘â€ğŸ« Training Optimized Reference-based gimVI...\")\n",
    "    trainer.fit(model, datamodule=datamodule)\n",
    "    \n",
    "    if is_save_ckpt:\n",
    "        best_ckpt_path = os.path.join(ckpt_dir, \"best_ckpts.yaml\")\n",
    "        callbacks[1].to_yaml(filepath=best_ckpt_path)\n",
    "    \n",
    "    # åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæµ‹è¯•\n",
    "    args.ckpt_path = callbacks[1].best_model_path\n",
    "    if args.ckpt_path:\n",
    "        model = OptimizedFixedReferenceBasedGimVI.load_from_checkpoint(args.ckpt_path, **args.__dict__)\n",
    "\n",
    "# æµ‹è¯•\n",
    "print(\"ğŸ¯ Testing Optimized Reference-based gimVI...\")\n",
    "test_results = trainer.test(model, datamodule=datamodule)\n",
    "print(\"âœ… Optimized Reference-based gimVI experiment completed!\")\n",
    "print(f\"Test results: {test_results}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
